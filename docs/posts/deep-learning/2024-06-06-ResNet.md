---
title: ResNet
date: 2024-06-06
tags:
    - 论文
    - 深度学习
    - CNN
---

Deep Residual Learning for Image Recognition

---

## 引入

深度卷积神经网络经典之作,2015年ImageNet大规模视觉识别挑战赛冠军

[论文PDF地址](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
    
## 主要概念

引入残差块,使得CNN可以训练的更深

对于下一个的模块,设原训练的输入为$x$,我们不再训练$f(x)$而是训练$f(x)-x$然后残差链接的加上这个x再输出



## 具体细节

对于输入输出考虑到可能相同可能不同,论文中提出3中方案:

1. 对于不同的时候补0
2. 对于不同的时候使用一个1x1的卷积层做投影
3. 对于所有时候都加入1x1的卷积层做投影

其中2与3效果较好,但是3计算量显然会大,所以现在我们一般都用方法2

### Bottleneck

对于较深的CNN网络,为了加速运算我们会对信息先投影到低维计算,然后再投影回高维加上残差

## 为什么有效

更多的是有效的保持了原始的梯度,避免了梯度的消失和不稳定


## 其他

- SGD收敛!=较优解,收敛也很可能是train不动
- 尽量保持梯度够大,这样慢慢的SGD收敛的结果会比较好